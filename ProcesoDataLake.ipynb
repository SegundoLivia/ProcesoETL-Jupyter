{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\edarcarto\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "dfgrau = pd.read_csv('../EPSGRAU/eseptiembre2024.csv', sep=',', encoding='ISO-8859-1')\n",
    "dfgrau = dfgrau.drop('fecha_dataclie', axis=1) \n",
    "dfgrau = dfgrau.drop('o_cant_periodos_facturados', axis=1)\n",
    "#Remplazar codigo de zonal por el nombre que les pertenece\n",
    "def asignar_valorzonal(row):\n",
    "    if pd.isna(row['v_id_provincia']):\n",
    "        return 'Identificarzonal' # Si v_id_provincia es NaN\n",
    "    elif row['v_id_provincia'] ==1:\n",
    "        return 'PIURA'\n",
    "    elif row['v_id_provincia']==4:\n",
    "        return 'CHULUCANA'\n",
    "    elif row['v_id_provincia']==5:\n",
    "        return 'PAITA'\n",
    "    elif row['v_id_provincia']==6:\n",
    "        return 'SULLANA'\n",
    "    elif row['v_id_provincia']==7:\n",
    "        return 'TALARA'\n",
    "    else:\n",
    "        return 'No tiene zonal'\n",
    "\n",
    "# Aplicar la función de reemplazo de zonal\n",
    "dfgrau['v_id_provincia'] = dfgrau.apply(asignar_valorzonal, axis=1)\n",
    "\n",
    "#Reempla\n",
    "def asignar_valorlocalidad(row):\n",
    "    if pd.isna((row['v_id_provincia']) or (row['v_id_distrito'])):\n",
    "        return 'Identificarzonal' # Si CAMPO1 es NaN, CAMPO2 toma el valor de CAMPO3\n",
    "    elif ((row['v_id_provincia']=='PIURA') & (row['v_id_distrito'] ==1)):\n",
    "        return 'PIURA'\n",
    "    elif ((row['v_id_provincia']=='PIURA') & (row['v_id_distrito'] ==2)):\n",
    "        return 'LAS LOMAS'\n",
    "    elif ((row['v_id_provincia']=='PIURA') & (row['v_id_distrito'] ==4)):\n",
    "        return 'CASTILLA'\n",
    "    elif ((row['v_id_provincia']=='PIURA') & (row['v_id_distrito'] ==5)):\n",
    "        return 'CATACAOS'\n",
    "    elif ((row['v_id_provincia']=='TALARA') & (row['v_id_distrito'] ==1)):\n",
    "        return 'TALARA'\n",
    "    elif ((row['v_id_provincia']=='TALARA') & (row['v_id_distrito'] ==2)):\n",
    "        return 'EL ALTO'\n",
    "    elif ((row['v_id_provincia']=='TALARA') & (row['v_id_distrito'] ==5)):\n",
    "        return 'LA BREA'\n",
    "    elif ((row['v_id_provincia']=='TALARA') & (row['v_id_distrito'] ==5)):\n",
    "        return 'LOS ORGANOS'\n",
    "    elif ((row['v_id_provincia']=='TALARA') & (row['v_id_distrito'] ==6)):\n",
    "        return 'MANCORA'\n",
    "    else:\n",
    "        return 'No tiene zonal'\n",
    "\n",
    "# Aplicar la función al DataFrame fila por fila\n",
    "dfgrau['v_id_distrito'] = dfgrau.apply(asignar_valorlocalidad, axis=1)\n",
    "valorgrau=21\n",
    "dfgrau.insert(0,'codigoeps',valorgrau)\n",
    "\n",
    "dfepsel= pd.read_csv('../CHICLAYO/epselset2024.csv', sep=',', encoding='ISO-8859-1')\n",
    "valorepsel=9\n",
    "dfepsel.insert(0,'codigoeps',valorepsel)\n",
    "dfepsel=dfepsel.drop('o_cant_per', axis=1)\n",
    "#dfepsel['v_cobranza']=dfepsel['pago_mes']\n",
    "#dfepsel=dfepsel.drop('pago_mes', axis=1)\n",
    "dftumb = pd.read_csv('../TUMBES/esetiembre2024.csv', sep=';', encoding='ISO-8859-1')\n",
    "valortumb=19\n",
    "dftumb.insert(0,'codigoeps',valortumb)\n",
    "\n",
    "dfica = pd.read_csv('../ICA/iseptiembre2024.csv', sep=';', encoding='ISO-8859-1')\n",
    "#df_g['v_fecha_ult_facturacion'] = pd.to_datetime(df_g['v_fecha_ult_facturacion'], format='%d/%m/%Y')\n",
    "#df_g['v_fecha'] = df_g['v_fecha_ult_facturacion'].astype(str)\n",
    "\n",
    "valorepica=12\n",
    "dfica.insert(0,'codigoeps',valorepica)\n",
    "dfica = dfica.drop('o_cant_periodos_facturados', axis=1)\n",
    "\n",
    "nuevos_nombres = ['codigoeps','nombre_eps','v_num_inscripcion','v_id_provincia','v_id_distrito','v_id_sector','v_id_manzana','v_id_ciclo','v_nombre_zona',\n",
    "'v_nombre_via','v_num_habitantes','v_num_pisos','v_id_estado_predio','v_id_tipo_servicio_t','v_estado_facturacion','v_estado_toma_lecturas','v_desc_grupo',\n",
    "'v_volumen_promedio','v_id_ruta_lectura','v_num_ruta_reparto','v_vol_fact','v_periodo_facturacion','v_medido','v_promedio','v_asignado',\n",
    "'v_categoria_principal','v_id_situacion_conagua','v_id_situacion_codesa','v_fecha_conagua','v_fecha_codesa','v_presion_conexion_en_mca','v_id_medidor',\n",
    "'v_diametro_medidor','v_fecha_instalacion_med','v_estado_medidor','v_fact_mes','v_fecha_primer_facturacion','v_fecha_ult_facturacion',\n",
    "'v_saldo_cta_cte','v_total_deuda_rec_fact','v_pagado','v_rec_pend','v_num_convenio','v_fecha_convenio','v_ult_fecha_corte','v_ult_fecha_reapertura',\n",
    "'v_desc_sector_comercial','v_fecha_ult_pago','v_ult_tipo_pago','v_tipo_recaudador','v_recaudador','v_cobranza_mes_1','v_cobranza_mes_2','v_cobranza_mes_3',\n",
    "'v_fecha_venci_ulti_recibo_emitido','o_cant_recibo_pagados','o_importe_total_pagado']\n",
    "dfgrau.columns = nuevos_nombres\n",
    "dfgrau= dfgrau[dfgrau['v_fecha_ult_facturacion'].notna() & (dfgrau['v_fecha_ult_facturacion'] != '')]\n",
    "dfgrau['v_fecha'] = dfgrau['v_fecha_ult_facturacion'].astype(str)\n",
    "\n",
    "dfepsel.columns = nuevos_nombres\n",
    "dfica.columns = nuevos_nombres\n",
    "dftumb.columns = nuevos_nombres\n",
    "\n",
    "df_g = pd.concat([dfgrau,dftumb,dfica,dfepsel], ignore_index=True)\n",
    "df_g = df_g.drop_duplicates(subset='v_num_inscripcion')\n",
    "df_g = df_g[df_g['v_fecha_ult_facturacion'].notna() & (df_g['v_fecha_ult_facturacion'] != '')]\n",
    "df_g['v_fecha'] = df_g['v_fecha_ult_facturacion'].astype(str)\n",
    "df_g['v_fecha_instalacion_med'] = pd.to_datetime(df_g['v_fecha_instalacion_med'], errors='coerce')\n",
    "df_g['v_fecha_instalacion_med'] = df_g['v_fecha_instalacion_med'].dt.strftime('%d/%m/%Y')\n",
    "df_g['v_fecha_instalacion_med'] = df_g['v_fecha_instalacion_med'].astype(str)\n",
    "df_g['fecham'] = pd.to_datetime(df_g['v_fecha_instalacion_med'])\n",
    "# Extraer el año y mes\n",
    "df_g['mes_v'] = df_g['fecham'].dt.month\n",
    "df_g['ano_v'] = df_g['fecham'].dt.year\n",
    "\n",
    "# Obtener la fecha actual\n",
    "#fecha_actual = datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "#df_g = pd.DataFrame(df_g)\n",
    "df_g.loc[(df_g['v_asignado']>0), ['v_promedio', 'v_medido']] = np.nan\n",
    "df_g.loc[(df_g['v_medido']>0), ['v_promedio', 'v_asignado']] = np.nan\n",
    "df_g.loc[(df_g['v_promedio']>0), ['v_medido', 'v_asignado']] = np.nan\n",
    "\n",
    "df_g.loc[df_g['v_asignado'] == 0, 'v_promedio'] = df_g['v_asignado']\n",
    "df_g.loc[(df_g['v_asignado'] == 0), 'v_asignado'] = np.nan\n",
    "\n",
    "df_g.loc[(df_g['v_estado_medidor']!='OPERATIVO') & (df_g['v_promedio']==0), ['v_medido']] = np.nan\n",
    "df_g.loc[(df_g['v_estado_medidor']=='OPERATIVO') & (df_g['v_promedio']==0), ['v_promedio']] = np.nan\n",
    "\n",
    "df_g['tconsumo']='Asignado'\n",
    "df_g.loc[df_g['v_medido'].notna(), ['tconsumo']] = 'Medido'\n",
    "df_g.loc[df_g['v_promedio'].notna(), ['tconsumo']] = 'Promedio'\n",
    "df_g.loc[df_g['v_asignado'].notna(), ['tconsumo']] = 'Asignado'\n",
    "\n",
    "#df_g.update(df_g)\n",
    "df_g.loc[df_g['v_categoria_principal'].isin(['DOMESTICA 1', 'DOMESTICA 2','DOMESTICA']),'v_categoria_principal'] = 'DOMESTICO'\n",
    "\n",
    "\n",
    "def asignar_valorfiel(v_pagado):\n",
    "    # Revisar si CAMPO1 es 0, vacío o NaN\n",
    "    #if v_cobranza_mes_1 == 0 or pd.isna(v_cobranza_mes_1) or v_cobranza_mes_1 == '':\n",
    "    if v_pagado == 'NO' or v_pagado == 'N' or pd.isna(v_pagado) or v_pagado == '':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df_g['fiel'] = df_g['v_pagado'].apply(asignar_valorfiel)\n",
    "\n",
    "def asignar_valorconsumo(row):\n",
    "    if pd.isna(row['v_vol_fact']):\n",
    "        return row['v_categoria_principal']  # Si CAMPO1 es NaN, CAMPO2 toma el valor de CAMPO3\n",
    "    elif row['v_vol_fact'] > 99:\n",
    "        return 'ALTOS CONSUMIDORES'\n",
    "    elif row['v_vol_fact'] < 6:\n",
    "        return 'BAJOS CONSUMIDORES'\n",
    "    else:\n",
    "        return row['v_categoria_principal']\n",
    "\n",
    "# Aplicar la función al DataFrame fila por fila\n",
    "df_g['clasificaconsumo'] = df_g.apply(asignar_valorconsumo, axis=1)\n",
    "\n",
    "def asignar_valorrangoconsumo(v_vol_fact):\n",
    "    if pd.isna(v_vol_fact):\n",
    "        return 'Sin consumo'  # Manejo de NaN si es necesario\n",
    "    elif v_vol_fact == 0:\n",
    "        return 'Consumos Ceros'\n",
    "    elif v_vol_fact <= 5:\n",
    "        return 'Entre 01 a 5 M3'\n",
    "    elif v_vol_fact <= 20:\n",
    "        return 'Entre 06 a 20 M3'\n",
    "    elif v_vol_fact <= 100:\n",
    "        return 'Entre 21 a 100 M3'\n",
    "    else:\n",
    "        return 'Mayor a 100'\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df_g['rangoconsumo'] = df_g['v_vol_fact'].apply(asignar_valorrangoconsumo)\n",
    "\n",
    "def asignar_rangoreciboDeuda(v_rec_pend):\n",
    "    if pd.isna(v_rec_pend):\n",
    "        return 'Sin consumo'  # Manejo de NaN si es necesario\n",
    "    elif v_rec_pend == 0:\n",
    "        return 'Deuda 0 Mes'\n",
    "    elif v_rec_pend <= 2:\n",
    "        return 'Deuda 01 a 02 Meses'\n",
    "    elif v_rec_pend <= 6:\n",
    "        return 'Deuda 03 a 06 Meses'\n",
    "    elif v_rec_pend <= 12:\n",
    "        return 'Deuda 07 a 12 M3'\n",
    "    else:\n",
    "        return 'Deuda de 12 a mas Meses'\n",
    "    \n",
    "# Aplicar la función al DataFrame\n",
    "df_g['rangorecibosdeuda'] = df_g['v_rec_pend'].apply(asignar_rangoreciboDeuda)\n",
    "\n",
    "rangorecibosdeuda = df_g.groupby(['codigoeps','v_id_provincia','v_id_distrito','v_id_sector','v_fecha','v_categoria_principal','rangorecibosdeuda']).agg(\n",
    "conexiones=('codigoeps', 'count'),  \n",
    "v_total_deuda_rec_fact=('v_total_deuda_rec_fact', 'sum'),\n",
    "v_saldo_cta_cte=('v_saldo_cta_cte', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "resultadoClasificacionConsumo = df_g.groupby(['codigoeps','v_id_provincia','v_id_distrito','v_id_sector','v_fecha','v_categoria_principal','clasificaconsumo','rangoconsumo']).agg(\n",
    "v_medido=('v_medido', 'sum'),\n",
    "v_promedio=('v_promedio', 'sum'),\n",
    "v_asignado=('v_asignado', 'sum'),\n",
    "conexiones=('codigoeps', 'count'),       \n",
    "v_fact_mes=('v_fact_mes', 'sum'),\n",
    "v_total_deuda_rec_fact=('v_total_deuda_rec_fact', 'sum'),\n",
    "v_cobranza_mes_1=('v_cobranza_mes_1', 'sum'),\n",
    "pagaron=('fiel', 'sum')    \n",
    ").reset_index()\n",
    "\n",
    "#clasificacionConsumo= pd.read_csv('G:/Unidades compartidas/Dirección de Operaciones/SEGUNDOLIVIA/DATALIKE/COMERCIAL/epsConsolidado_2024.csv', sep=';', encoding='ISO-8859-1')\n",
    "\n",
    "#consolidado = pd.concat([clasificacionConsumo,resultadoClasificacionConsumo], ignore_index=True)\n",
    "\n",
    "resultadoRangoConsumo = df_g.groupby(['codigoeps','v_id_provincia','v_id_distrito','v_id_sector','v_fecha','v_categoria_principal','tconsumo','rangoconsumo']).agg(\n",
    "v_medido=('v_medido', 'sum'),\n",
    "v_promedio=('v_promedio', 'sum'),\n",
    "v_asignado=('v_asignado', 'sum'),\n",
    "conexiones=('codigoeps', 'count'),       \n",
    "v_cobranza_mes_1=('v_cobranza_mes_1', 'sum'),\n",
    "pagaron=('fiel', 'sum')        \n",
    ").reset_index()\n",
    "\n",
    "resultadoImporteTotal = df_g.groupby(['codigoeps','v_id_provincia','v_id_distrito','v_fecha']).agg(\n",
    "o_importe_total_pagado=('o_importe_total_pagado', 'sum'),      \n",
    "v_cobranza_mes_1=('v_cobranza_mes_1', 'sum'),\n",
    "pagaron=('fiel', 'sum')        \n",
    ").reset_index()\n",
    "\n",
    "\n",
    "#df_g['v_medido'] = df_g['v_medido'].astype(str)\n",
    "\n",
    "#df_g['v_medido'].notna()\n",
    "\n",
    "#filtered_df = df_g[(df_g['v_medido'].astype(float)>= 0)]\n",
    "#filtro = df_g['codigoeps'] == 19\n",
    "\n",
    "# Aplica el filtro y muestra los valores de campo1\n",
    "#resultadoRangoAnoMedidores= df_g[filtro]['v_medido']\n",
    "#print(resultadoRangoAnoMedidores)\n",
    "\n",
    "#resultadoRangoAnoMedidores = filtered_df.groupby(['codigoeps','v_id_provincia','v_id_distrito','v_fecha','ano_v','mes_v','v_categoria_principal','rangoconsumo']).agg(\n",
    "\n",
    "resultadoRangoAnoMedidores = df_g.groupby(['codigoeps','v_id_provincia','v_id_distrito','v_fecha','ano_v','mes_v','v_categoria_principal','rangoconsumo']).agg(\n",
    "conexiones=('codigoeps', 'count')\n",
    ").reset_index()\n",
    "\n",
    "ahora = datetime.datetime.now()\n",
    "ano = ahora.strftime('%Y%m')  # Captura el día en formato 'año'\n",
    "dia = ahora.strftime('%Y%m%d')  # Captura el día en formato 'año-mes-día'\n",
    "hora = ahora.strftime('%H')  # Obtiene la hora actual en formato de dos dígitos\n",
    "minuto = ahora.strftime('%M')  # Obtiene el minuto actual\n",
    "segundo = ahora.strftime('%S')  # Obtiene el segundo actual\n",
    "\n",
    "epsClasConsumo= 'epsClasConsumo'\n",
    "epsRangoConsumo= 'epsRangoConsumo'\n",
    "epsRangoAnos= 'epsRangoAnosMedidores'\n",
    "epsImporteTotal= 'epsImporteTotal'\n",
    "epsTodo= 'epsTodo'\n",
    "epsConsolidado= 'epsConsolidado'\n",
    "epsRangoDeudaRecibo= 'epsRangoDeudaRecibo'\n",
    "nombre_epsTodo = f\"{epsTodo}_{dia}{hora}{minuto}{segundo}.csv\"\n",
    "ruta_epsTodo = os.path.join('../CHICLAYO',nombre_epsTodo)\n",
    "df_g.to_csv(ruta_epsTodo, index=False, sep=';')\n",
    "# Construye el nombre del archivo con los parámetros capturados\n",
    "nombre_epsRangoDeudaRecibo = f\"{epsRangoDeudaRecibo}_{dia}{hora}{minuto}{segundo}.csv\"\n",
    "ruta_archivoeRangoDeudaRecibo = os.path.join('G:/Unidades compartidas/Dirección de Operaciones/SEGUNDOLIVIA/DATALIKE/COMERCIAL/RangoDeudaRecibo/',nombre_epsRangoDeudaRecibo)\n",
    "rangorecibosdeuda.to_csv(ruta_archivoeRangoDeudaRecibo, index=False, sep=';')\n",
    "\n",
    "nombre_epsClasConsumo = f\"{epsClasConsumo}_{dia}{hora}{minuto}{segundo}.csv\"\n",
    "ruta_archivoepsClasConsumo = os.path.join('G:/Unidades compartidas/Dirección de Operaciones/SEGUNDOLIVIA/DATALIKE/COMERCIAL/CobranzaFacturacion/',nombre_epsClasConsumo)\n",
    "resultadoClasificacionConsumo.to_csv(ruta_archivoepsClasConsumo, index=False, sep=';')\n",
    "\n",
    "nombre_epsRangoConsumo = f\"{epsRangoConsumo}_{dia}{hora}{minuto}{segundo}.csv\"\n",
    "ruta_archivoepsRangoConsumo = os.path.join('G:/Unidades compartidas/Dirección de Operaciones/SEGUNDOLIVIA/DATALIKE/COMERCIAL/RangosConsumos/',nombre_epsRangoConsumo)\n",
    "resultadoRangoConsumo.to_csv(ruta_archivoepsRangoConsumo, index=False, sep=';')\n",
    "\n",
    "nombre_epsRangoAnos = f\"{epsRangoAnos}_{dia}{hora}{minuto}.csv\"\n",
    "ruta_archivoepsRangoAnos = os.path.join('../CHICLAYO',nombre_epsRangoAnos)\n",
    "resultadoRangoAnoMedidores.to_csv(ruta_archivoepsRangoAnos, index=False, sep=';')\n",
    "\n",
    "nombre_epsepsImporteTotal= f\"{epsImporteTotal}_{dia}.csv\"\n",
    "ruta_archivoepsImporteTotal = os.path.join('../CHICLAYO',nombre_epsepsImporteTotal)\n",
    "resultadoImporteTotal.to_csv(ruta_archivoepsImporteTotal, index=False, sep=';')\n",
    "\n",
    "#nombre_epsConsolidado= f\"{epsConsolidado}_{ano}.csv\"\n",
    "#ruta_archivoeepsConsolidado = os.path.join('G:/Unidades compartidas/Dirección de Operaciones/SEGUNDOLIVIA/DATALIKE/COMERCIAL/CobranzaFacturacion/',nombre_epsConsolidado)\n",
    "#consolidado.to_csv(ruta_archivoeepsConsolidado, index=False, sep=';')\n",
    "\n",
    "#desde aqui hay que anular por el momento, hasta corregir el formato de fechas\n",
    "# Variables\n",
    "#directorio = '../CHICLAYO'\n",
    "#nombre_archivo = nombre_archivo\n",
    "# Crear la ruta completa\n",
    "#ruta_completa = f\"{directorio}/{nombre_archivo}\"\n",
    "\n",
    "# Leer el archivo CSV\n",
    "#df = pd.read_csv(ruta_completa)\n",
    "#df=pd.read_csv(ruta_completa, sep=';', encoding='ISO-8859-1')\n",
    "#df['v_fecha'] = pd.to_datetime(df['v_fecha'], format='%d-%m-%Y')\n",
    "#df['ano']=df['v_fecha']\n",
    "# Extraer el año y el mes\n",
    "#df['año'] = df['v_fecha'].dt.year\n",
    "#df['mes'] = df['v_fecha'].dt.month\n",
    "\n",
    "#print(f\"Archivo guardado como: {ruta_archivo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 5800742: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Leer el archivo CSV como texto\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLibro2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 5\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Reemplazar los delimitadores múltiples con una coma\u001b[39;00m\n\u001b[0;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Reemplaza punto y coma con coma\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\edarcarto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 5800742: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer el archivo CSV como texto\n",
    "with open('Libro2.csv', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Reemplazar los delimitadores múltiples con una coma\n",
    "data = data.replace(';', ',')  # Reemplaza punto y coma con coma\n",
    "data = data.replace('|', ',')  # Reemplaza barra vertical con coma\n",
    "\n",
    "# Guardar el texto procesado en un nuevo archivo CSV\n",
    "with open('archivo_procesado.csv', 'w') as file:\n",
    "    file.write(data)\n",
    "\n",
    "# Leer el archivo procesado con pandas\n",
    "df = pd.read_csv('archivo_procesado.csv', sep=',')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen por año:\n",
      "            nombre_eps  v_num_inscripcion         v_id_provincia  \\\n",
      "0       EPS GRAU S. A.                282                      1   \n",
      "1       EPS GRAU S. A.                737                      1   \n",
      "2       EPS GRAU S. A.               1089                      1   \n",
      "3       EPS GRAU S. A.             276046                      5   \n",
      "4       EPS GRAU S. A.            1085547                      4   \n",
      "...                ...                ...                    ...   \n",
      "308087     AGUA TUMBES            1284006  CONTRALMIRANTE VILLAR   \n",
      "308088     AGUA TUMBES            1284007  CONTRALMIRANTE VILLAR   \n",
      "308089     AGUA TUMBES            1237832  CONTRALMIRANTE VILLAR   \n",
      "308090     AGUA TUMBES             283689  CONTRALMIRANTE VILLAR   \n",
      "308091     AGUA TUMBES            1239314  CONTRALMIRANTE VILLAR   \n",
      "\n",
      "       v_id_distrito  v_id_sector  v_id_manzana  v_id_ciclo  \\\n",
      "0                  5            2           450           1   \n",
      "1                  5            7            26           1   \n",
      "2                  5            7            10           1   \n",
      "3                  4            2            18           1   \n",
      "4                  1            3            36           1   \n",
      "...              ...          ...           ...         ...   \n",
      "308087      ZORRITOS           46          1250          72   \n",
      "308088      ZORRITOS           47          1280          72   \n",
      "308089      ZORRITOS           46           380          35   \n",
      "308090      ZORRITOS           47           720          17   \n",
      "308091      ZORRITOS           46           380          16   \n",
      "\n",
      "             v_nombre_zona  v_nombre_via  \n",
      "0                CERCADO H  LOS SECHURAS  \n",
      "1                   MOCARA      PROGRESO  \n",
      "2                   MOCARA    SIN NOMBRE  \n",
      "3       SAN LUCAS DE COLAN    JOSE OLAYA  \n",
      "4                  CERCADO        CALLAO  \n",
      "...                    ...           ...  \n",
      "308087                 NaN           NaN  \n",
      "308088                 NaN           NaN  \n",
      "308089                 NaN           NaN  \n",
      "308090                 NaN           NaN  \n",
      "308091                 NaN           NaN  \n",
      "\n",
      "[308092 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "cs = df1[['nombre_eps','v_num_inscripcion','v_id_provincia','v_id_distrito','v_id_sector','v_id_manzana','v_id_ciclo','v_nombre_zona','v_nombre_via']]\n",
    "cs1 =df2[['nombre_eps','v_num_inscripcion','v_id_provincia','v_id_distrito','v_id_sector','v_id_manzana','v_id_ciclo','v_nombre_zona','v_nombre_via']]\n",
    "##,'v_id_sector','v_id_manzana','v_id_ciclo','v_nombre_zona','v_nombre_via','v_num_habitantes','v_num_pisos','v_id_estado_predio','v_id_tipo_servicio_t','v_estado_facturacion'\n",
    "\n",
    "#Jun tamos los 03 dataframe en uno solo, con la funcion concat\n",
    "df_g = pd.concat([cs,cs1], ignore_index=True)\n",
    "\n",
    "#Creamos una nueva columna, la llamamos año en el dataframe\n",
    "#Con la funcion de Python str, substraemos los 04 valores del campo fecha, por ser un campo string\n",
    "#df_g['año'] = df_g['Fecha'].str[:4]\n",
    "#Creamos una nueva columna ventas en el dataframe\n",
    "#El valor de la nueva columna Ventas, sera calculada por dos campos\n",
    "#Cantidad Vendida * Precio Unitario\n",
    "#df_g['Ventas']  = df_g['Cantidad Vendida'] * df_g['Precio Unitario']\n",
    "\n",
    "#Total_Ventas = venta.groupby('AÑO')['Ventas'].sum()\n",
    "\n",
    "#Vamos a utilizar dos funciones de Python groupby y agg\n",
    "# Con groupby vamos a agrupar por el campo que seleccionemos\n",
    "# Con agg, podemos crear varios funciones que se almacenen en una sola variable\n",
    "#Agrupar por año y las ventas\n",
    "#resultado = df_g.groupby(['año']).agg(\n",
    "#   Total_ventas=('Ventas', 'sum')\n",
    "#).reset_index()\n",
    "#Total de ventas por categoría y año.\n",
    "# utilizamos agg para realizar las operaciones como son Cantidad Vendidad, ventas, y promedio de Precio Promedio\n",
    "#Utilizamos reset_index para creaer los indices del reporte del Dataframe\n",
    "##resultado2 = df_g.groupby(['año', 'Categoria']).agg(\n",
    "##          cantidad_ventas=('Cantidad Vendida', 'count'),\n",
    "    ##            Total_ventas=('Ventas', 'sum'),\n",
    "    ##promedio_precio_unitario=('Precio Unitario', 'mean')\n",
    "##).reset_index()\n",
    "#Promedio de precio unitario por categoría, se hizo por separa el calculo del promedio\n",
    "# Utilizamos la funcion mean para calcular el promedio\n",
    "##resultado3 = df_g.groupby(['Categoria']).agg(\n",
    "    # ##  promedio_precio_unitario=('Precio Unitario', 'mean')\n",
    "##).reset_index()\n",
    "# Encontrar el producto más vendido por año\n",
    "#Agrupamos por año y producto\n",
    "# sumamos el campo Cantidad Vendidas conla funcion sum\n",
    "##producto_mas_vendido = df_g.groupby(['año', 'Producto'])['Cantidad Vendida'].sum().reset_index()\n",
    "#Ordenamos por año y Cantidad Vendida de manera ascendente\n",
    "##producto_mas_vendido = producto_mas_vendido.sort_values(['año', 'Cantidad Vendida'], ascending=[True, False])\n",
    "# Eliminar duplicados por el campo año\n",
    "##producto_mas_vendido = producto_mas_vendido.drop_duplicates(subset=['año'])\n",
    "\n",
    "# Identificar los productos con disminución de ventas en el segundo año\n",
    "# Agrupamos por año y producto\n",
    "# La función unstack() se utiliza para transformar el índice de un DataFrame de nivel de filas a nivel de columnas\n",
    "# básicamente pivotando el DataFrame, Esta operacion permite reorganizar los datos para un análisis más fácil o para preparar los datos para visualización.\n",
    "# fillna(0) convierte en 0 cundo encuentra NaN\n",
    "##ventas_por_producto = df_g.groupby(['año', 'Producto'])['Cantidad Vendida'].sum().unstack().fillna(0)\n",
    "##print(ventas_por_producto) \n",
    "# La función diff() calculamos la diferencia entre las cantidades vendidas por producto.\n",
    "# Es especialmente útil para calcular cambios entre valores consecutivos en una serie temporal\n",
    "# La operación iloc < 0 se utiliza para acceder a un valor específico en un DataFrame o \n",
    "# Serie utilizando el índice basado en la posición (índice entero) y luego comparar ese valor con 0.\n",
    "##productos_disminucion = ventas_por_producto.diff().iloc[1] < 0\n",
    "#convertimos en un lista\n",
    "##productos_disminucion = productos_disminucion[productos_disminucion].index.tolist()\n",
    "# Imprimir los resultados\n",
    "print(\"Resumen por año:\")\n",
    "#print(df_g1)\n",
    "print(df_g)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Producto más vendido por año:\n",
      "\n",
      "---\n",
      "     año Producto  Cantidad Vendida\n",
      "12  2021    Leche               647\n",
      "33  2022      Pan               601\n",
      "42  2023   Azúcar               495\n",
      "Promedio de precio unitario por categoría:\n",
      "\n",
      "---\n",
      "           Categoria  promedio_precio_unitario\n",
      "0            Bebidas                 10.145122\n",
      "1  Frutas y Verduras                 10.835412\n",
      "2             Granos                 10.761477\n",
      "3           Limpieza                 10.111895\n",
      "4            Lácteos                 10.414189\n",
      "5          Panadería                 10.612951\n",
      "6          Proteínas                 10.631349\n",
      "7             Snacks                  9.665484\n",
      "\n",
      "Productos con disminución de ventas en el segundo año:\n",
      "\n",
      "---\n",
      "['Azúcar', 'Café', 'Cereal', 'Cerveza', 'Detergente', 'Frutas', 'Jabón', 'Leche', 'Sal', 'Vino']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nProducto más vendido por año:\")\n",
    "print(\"\\n---\")\n",
    "print(producto_mas_vendido)\n",
    "print(\"Promedio de precio unitario por categoría:\")\n",
    "print(\"\\n---\")\n",
    "print(resultado3)\n",
    "print(\"\\nProductos con disminución de ventas en el segundo año:\")\n",
    "print(\"\\n---\")\n",
    "print(productos_disminucion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calcular estadísticas descriptivas:\n",
      "\n",
      "---\n",
      "       Cantidad Vendida  Precio Unitario      Ventas\n",
      "count        900.000000       900.000000  900.000000\n",
      "mean          25.611111        10.435022  267.333656\n",
      "std           14.849182         5.426371  221.178019\n",
      "min            1.000000         1.040000    2.050000\n",
      "25%           13.000000         5.785000   88.095000\n",
      "50%           26.000000        10.330000  206.325000\n",
      "75%           39.000000        15.105000  400.582500\n",
      "max           50.000000        19.970000  914.830000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalcular estadísticas descriptivas:\")\n",
    "print(\"\\n---\")\n",
    "print(df_g.describe())\n",
    "#df_g.info()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el Dataframe\n",
    "df_g.to_csv('archivo_generarl.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Producto:\n",
    "    def __init__(self, id_producto, nombre, categoria_id, precio):\n",
    "        self.id_producto = id_producto\n",
    "        self.nombre = nombre\n",
    "        self.categoria_id = categoria_id\n",
    "        self.precio = precio\n",
    "\n",
    "class Venta:\n",
    "    def __init__(self, id_venta, id_producto, cantidad, fecha):\n",
    "        self.id_venta = id_venta\n",
    "        self.id_producto = id_producto\n",
    "        self.cantidad = cantidad\n",
    "        self.fecha = fecha\n",
    "\n",
    "class Categoria:\n",
    "    def __init__(self, id_categoria, nombre):\n",
    "        self.id_categoria = id_categoria\n",
    "        self.nombre = nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductoAlimenticio(Producto):\n",
    "    # Tambien definimos su propio atributo de la clase hija, como es goles_marcados\n",
    "    def __init__(self, nombre,categoria_id, precio,):\n",
    "        # llamamos a la clase padre(super clase) y heredando sus atributos nombre y duracion\n",
    "        super().__init__(nombre,categoria_id, precio)\n",
    "    \n",
    "        \n",
    "class ProductoNoAlimenticio(Producto):\n",
    "    # Tambien definimos su propio atributo de la clase hija, como es goles_marcados\n",
    "    def __init__(self, nombre,categoria_id, precio,):\n",
    "        # llamamos a la clase padre(super clase) y heredando sus atributos nombre y duracion\n",
    "        super().__init__(nombre,categoria_id, precio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados: [2046.6, 2065.75, 2239.65, 2444.8, 2536.14, 2117.04, 2510.84, 2052.55, 2143.8, 2662.41, 2662.2, 2280.05, 2576.0, 2091.23, 2261.61, 2056.15, 2521.66, 2140.4, 2205.3, 2127.1, 2811.8, 2043.09, 2149.92, 2751.85, 2076.88, 2152.44, 2247.6, 2361.52, 2045.1, 2378.0, 2462.68, 2078.24, 2279.04, 2078.1, 2227.32, 2354.84, 2270.59, 2589.58, 2254.6, 2179.2, 2347.6, 2415.64, 2507.33, 2100.16, 2039.4, 2279.9, 2355.92, 2647.85, 2095.7, 2066.45, 2873.46, 2095.0, 2305.8, 2151.68, 2494.14, 2051.32, 2684.8, 2238.79, 2028.63, 2203.59, 2351.55, 2462.8, 2212.0, 2112.52, 2436.2799999999997, 2070.4, 2565.62, 2783.19, 2100.35, 2100.52, 2642.81, 2317.52, 2709.0, 2316.51, 2148.84, 2726.76, 2063.75, 2286.16, 2127.06, 2631.94, 2532.5, 2155.73, 2720.46, 2130.4, 2345.6, 2277.08, 2463.34, 2226.04, 2303.88, 2670.29, 2223.32, 2101.72, 2133.5, 2037.2, 2680.04, 2513.56, 2239.32, 2223.75, 2465.24, 2309.9, 2166.28, 2138.3, 2077.55, 2127.19, 2039.4, 2124.36, 2041.88, 2151.44, 2458.5, 2226.68, 2081.08, 2154.3, 2522.09, 2201.9, 2242.51, 2218.75, 2193.12, 2305.25, 2062.04, 2253.3, 2043.7, 2385.6, 2224.63, 2365.2, 2136.28, 2046.16, 2125.6, 2585.55, 2058.24, 2218.87, 2445.71, 2042.9, 2067.25, 2503.74, 2251.34, 2718.13, 2862.92, 2689.51, 2094.08, 2026.71, 2231.65, 2025.88, 2137.57, 2931.46, 2103.32, 2171.68, 2115.56, 2309.48, 2797.7, 2693.3, 2324.8, 2346.12, 2220.8, 2249.26, 2682.03, 2446.4, 2240.49, 2350.01, 2122.6, 2249.78, 2675.32, 2176.5, 2234.86, 2568.56, 2564.17, 2661.35, 2058.1, 2311.6, 2404.0, 2038.54, 2106.4, 2833.35, 2758.13, 2026.18, 2468.04, 2423.81, 2448.36, 2036.04, 2195.1, 2450.4, 2312.16, 2513.49, 2207.5, 2175.6, 2327.74, 2198.35, 2175.8, 2120.84, 2438.5, 2031.96, 2877.5, 2487.92, 2306.95, 2207.66, 2444.69, 2421.19, 2230.84, 2615.34, 2333.0, 2264.8, 2449.13, 2094.92, 2331.8, 2430.36, 2033.54, 2555.14, 2045.8, 2680.56, 2314.77, 2191.92, 2165.4, 2594.16, 2101.75, 2052.72, 2165.1, 2192.73, 2062.41, 2400.0, 2248.94, 2244.08, 2205.14, 2316.68, 2209.58, 2301.32, 2372.02, 2301.02, 2065.75, 2276.78, 2214.06, 2610.1, 2786.6, 2264.05, 2049.2, 2252.91, 2806.92, 2271.06, 2089.4, 2937.83, 2097.13, 2663.18, 2040.04, 2097.04, 2041.24, 2265.02, 2079.4, 2161.81, 2189.06, 2053.4, 2078.2, 2176.21, 2233.8, 2241.52, 2282.17, 2160.68, 2546.74, 2046.18, 2068.2, 2082.84, 2287.0, 2108.52, 2155.26, 2177.9, 2705.53, 2274.48, 2613.8, 2237.0, 2602.6800000000003, 2181.62, 2332.15, 2257.8, 2340.82, 2069.98, 2048.5, 2131.0, 2291.75, 2096.4, 2452.0, 2215.36, 2164.81, 2526.42, 2896.65, 2118.17, 2687.9300000000003, 2131.64, 2146.44, 2118.58, 2180.9, 2357.08, 2038.71, 2072.7, 2028.96, 2065.33, 2261.98, 2023.65, 2278.0, 2585.88, 2041.89, 2158.01, 2278.52, 2236.02, 2107.8, 2477.07, 2192.43, 2829.2200000000003, 2706.53, 2103.5, 2047.08, 2501.04, 2074.9, 2026.35, 2225.66, 2069.18, 2160.86, 2148.6, 2163.57, 2120.97, 2138.18, 2359.26, 2333.55, 2709.35, 2380.7200000000003, 2076.02, 2359.88, 2455.4, 2282.2, 2153.72, 2066.04, 2037.56, 2589.9300000000003, 2896.65, 2361.36, 2175.18, 2674.32, 2290.45, 2154.24, 2403.19, 2216.36, 2312.56, 2307.6, 2037.6, 2092.26, 2153.34, 2207.5, 2239.84, 2311.28, 2390.15, 2122.0, 2114.23, 2680.7, 2171.96, 2275.72, 2260.08, 2168.88, 2073.3, 2588.35, 2439.24, 2790.3, 2300.2799999999997, 2346.02, 2136.72, 2676.6, 2324.6, 2051.25, 2173.2, 2207.04, 2585.3, 2056.16, 2089.88, 2180.73, 2214.76, 2050.21, 2156.75, 2053.66, 2293.25, 2199.4, 2125.6, 2134.85, 2753.25, 2112.2, 2549.66, 2135.48, 2465.75, 2454.88, 2199.6, 2165.55, 2068.46, 2396.4, 2503.24, 2463.44, 2345.23, 2028.8, 2104.7, 2179.67, 2380.7200000000003, 2597.7799999999997, 2354.6, 2167.0, 2153.67, 2284.5, 2693.2200000000003, 2034.72, 2891.4, 2173.6, 2057.2, 2092.56, 2517.5, 2359.52, 2213.89, 2532.88, 2569.6800000000003, 2371.0, 2038.83, 2151.91, 2041.15, 2666.15, 2246.72, 2070.7, 2034.73, 2195.96, 2261.87, 2035.32, 2230.64, 2407.6, 2359.39, 2509.67, 2231.56, 2213.72, 2310.68, 2105.2, 2064.25, 2420.0, 2121.9, 2089.92, 2126.28, 2459.71, 2026.27, 2579.01, 2087.45, 2725.62, 2252.14, 2557.6, 2108.02, 2324.1, 2119.0, 2048.62, 2405.04, 2100.72, 2121.08, 2083.65, 2213.4700000000003, 2189.8, 2091.09, 2247.6, 2047.2, 2035.77, 2179.16, 2123.86, 2446.94, 2081.45, 2043.22, 2474.49, 2085.26, 2285.77, 2393.14, 2173.8, 2257.46, 2053.77, 2734.76, 2458.6, 2142.96, 2037.52, 2102.56, 2147.56, 2224.35, 2050.13, 2581.25, 2237.54, 2122.7, 2127.0, 2107.7, 2492.08, 2333.44, 2526.89, 2085.89, 2362.34, 2567.5299999999997, 2096.82, 2323.14, 2265.54, 2056.96, 2137.4, 2179.15, 2133.86, 2068.88, 2410.15, 2028.6, 2101.38, 2316.12, 2845.6, 2234.99, 2053.91, 2165.2, 2620.6, 2295.39, 2444.82, 2500.8, 2234.96, 2361.5, 2089.92, 2107.25, 2353.92, 2105.98, 2163.8, 2192.0, 2111.76, 2635.44, 2104.5, 2163.36, 2361.86, 2103.22, 2667.76, 2048.52, 2071.68, 2048.4, 2135.28, 2091.3, 2774.96, 2284.87, 2063.4, 2670.21, 2039.95, 2217.36, 2164.0, 2788.6, 2740.2, 2319.9, 2282.44, 2187.9700000000003, 2125.5, 2075.41, 2043.42, 2054.34, 2101.05, 2171.99, 2081.1, 2166.46, 2766.0, 2404.18, 2125.6, 2255.07, 2426.2, 2050.55, 2714.95, 2200.35, 2057.35, 2056.44, 2112.85, 2700.5, 2307.44, 2296.44, 2297.54, 2383.05, 2354.92, 2142.6, 2440.31, 2388.24, 2242.1, 2088.68, 2052.16, 2325.08, 2383.25, 2248.46, 2232.26, 2042.2, 2241.25, 2271.04, 2059.59, 2187.56, 2265.88, 2504.44, 2602.6, 2692.58, 2077.45, 2041.08, 2257.36, 2080.36, 2463.4700000000003, 2085.66, 2397.44, 2135.5, 2190.51, 2419.65, 2094.24, 2464.32, 2500.89, 2046.22, 2195.25, 2349.4, 2193.3, 2125.59, 2762.0, 2212.8, 2023.05, 2814.04, 2446.77, 2358.59, 2485.25, 2534.09, 2095.92, 2277.91, 2422.84, 2857.92, 2325.81, 2591.76, 2361.94, 2053.64, 2076.28, 2179.78, 2641.92, 2335.8, 2268.68, 2158.45, 2227.16, 2183.24, 2524.66, 2075.45, 2306.2, 2106.54, 2174.56, 2132.54, 2448.2799999999997, 2460.58, 2023.79, 2438.8, 2624.56, 2064.52, 2089.9, 2703.88, 2866.84, 2350.08, 2142.14, 2037.25, 2299.7799999999997, 2350.12, 2200.28, 2094.36, 2478.52, 2125.26, 2082.26, 2104.2, 2316.2799999999997, 2234.28, 2030.3, 2136.72, 2595.4, 2151.4, 2324.68, 2032.1, 2425.4, 2222.44, 2061.19, 2252.4, 2599.08, 2061.8, 2042.89, 2398.1, 2321.16, 2490.84, 2191.76, 2231.0, 2740.4300000000003, 2151.25, 2043.82, 2338.91, 2151.8, 2050.68, 2246.3, 2236.36, 2205.3, 2040.39, 2032.45, 2153.79, 2168.75, 2150.44, 2604.76, 2163.24, 2487.35, 2489.82, 2356.24, 2181.57, 2139.1, 2049.5, 2664.65, 2475.2, 2134.04, 2137.8, 2214.2, 2638.7799999999997, 2210.44, 2444.8, 2034.2, 2474.64, 2770.48, 2045.56, 2369.75, 2462.61, 2070.19, 2221.58, 2169.32, 2450.04, 2169.2, 2321.0, 2039.04, 2058.19, 2078.36, 2126.45, 2196.6, 2189.28, 2472.5, 2283.45, 2225.48, 2404.12, 2888.92, 2197.46, 2075.88, 2333.03, 2418.68, 2116.71, 2215.85, 2617.55, 2069.55, 2800.59, 2039.06, 2194.87, 2211.7, 2433.16, 2477.0, 2337.6, 2162.25, 2392.0, 2275.2, 2264.11, 2142.75, 2122.8, 2422.36, 2053.24, 2180.67, 2110.57, 2642.1, 2065.75, 2716.2, 2225.94, 2184.68, 2501.24, 2054.66, 2034.41, 2030.94, 2105.96, 2418.88, 2321.0, 2231.43, 2678.0, 2856.65, 2159.15, 2425.77, 2185.2, 2758.82, 2168.86, 2106.6, 2106.8, 2806.8, 2269.78, 2350.32, 2329.16, 2027.41, 2038.72, 2481.04, 2029.32, 2182.2, 2225.82, 2537.04, 2642.0699999999997, 2731.5299999999997, 2381.36, 2037.18, 2338.36, 2224.93, 2477.2799999999997, 2112.3, 2276.3, 2206.9, 2790.08, 2236.76, 2032.54, 2678.25, 2280.52, 2819.59, 2035.54, 2457.4, 2288.64, 2121.0, 2231.0, 2815.92, 2482.0, 2207.66, 2358.24, 2041.7, 2124.88, 2051.72, 2437.8, 2347.95, 2374.4, 2567.14, 2041.01, 2898.16, 2059.0, 2215.05, 2035.2, 2160.76, 2173.46, 2364.09, 2404.9, 2055.72, 2110.56, 2256.65, 2107.2, 2769.4, 2147.36, 2157.1, 2244.2, 2221.4, 2233.0, 2184.17, 2227.55, 2301.68, 2312.64, 2379.76, 2294.36, 2148.04, 2457.32, 2713.65, 2732.9, 2602.16, 2304.88, 2031.14, 2848.98, 2219.51, 2148.04, 2356.54, 2126.44, 2030.23, 2070.9, 2041.25, 2078.6, 2758.67, 2073.06, 2169.17, 2033.91, 2033.6, 2509.16, 2036.22, 2031.44, 2659.4, 2455.0, 2028.29, 2538.6, 2184.18, 2444.62, 2293.86, 2869.41, 2264.84, 2064.05, 2072.92, 2763.0, 2197.2, 2061.9, 2771.75, 2232.0, 2721.9300000000003, 2471.08, 2719.71, 2407.77, 2045.96, 2121.15, 2694.51, 2729.5, 2073.84, 2736.7200000000003, 2608.09, 2778.04, 2403.5, 2266.52, 2143.38, 2663.83, 2226.96, 2228.1, 2400.82, 2183.11, 2348.08, 2320.04]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def leer_csv(archivo):\n",
    "    try:\n",
    "        # Intenta leer el archivo CSV\n",
    "        datos = pd.read_csv('archivo_generarl.csv')\n",
    "        return datos\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: El archivo {archivo} no se encontró.\")\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: El archivo {archivo} está vacío.\")\n",
    "    except pd.errors.ParserError:\n",
    "        print(f\"Error: Ocurrió un problema al analizar el archivo {archivo}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado al leer el archivo: {e}\")\n",
    "\n",
    "def procesar_datos_csv(datos):\n",
    "    resultados = []\n",
    "    try:\n",
    "        # Supongamos que necesitamos dos columnas específicas: 'columna1' y 'columna2'\n",
    "        if 'año' not in datos.columns or 'Ventas' not in datos.columns:\n",
    "            raise KeyError(\"Faltan las columnas necesarias en los datos.\")\n",
    "        \n",
    "        for _, fila in datos.iterrows():\n",
    "            try:\n",
    "                num1 = float(fila['año'])\n",
    "                num2 = float(fila['Ventas'])\n",
    "                resultados.append(num1 + num2)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error de valor: {e} en la fila {fila}.\")\n",
    "            except KeyError as e:\n",
    "                print(f\"Error: Columna no encontrada {e} en la fila {fila}.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error inesperado al procesar la fila {fila}: {e}\")\n",
    "                \n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado al procesar los datos: {e}\")\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "def main():\n",
    "    archivo = 'archivo_generarl.csv'\n",
    "    \n",
    "    datos = leer_csv(archivo)\n",
    "    if datos is not None and not datos.empty:\n",
    "        resultados = procesar_datos_csv(datos)\n",
    "        print(\"Resultados:\", resultados)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
